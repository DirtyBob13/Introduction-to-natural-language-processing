{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf5e917",
   "metadata": {},
   "source": [
    "Тема «POS-tagger и NER»\n",
    "\n",
    "Задание 1. Написать теггер на данных с русским языком\n",
    "проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
    "написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "сравнить все реализованные методы, сделать выводы  \n",
    "\n",
    "\n",
    "Задание 2. Проверить, насколько хорошо работает NER\n",
    "Данные брать из Index of /pub/named_entities\n",
    "проверить NER из nltk/spacy/deeppavlov.\n",
    "написать свой NER, попробовать разные подходы.\n",
    "передаём в сетку токен и его соседей.\n",
    "передаём в сетку только токен.\n",
    "свой вариант.\n",
    "сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4e421",
   "metadata": {},
   "source": [
    "Задание 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a8b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyconll\n",
      "  Downloading pyconll-3.2.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: pyconll\n",
      "Successfully installed pyconll-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3767050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.4-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 12.2/12.2 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.2-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (1.25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp310-cp310-win_amd64.whl (480 kB)\n",
      "     -------------------------------------- 480.9/480.9 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.11-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 94.7/94.7 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.0-py3-none-any.whl (34 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.1.0 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.2 preshed-3.0.8 pydantic-1.10.11 spacy-3.5.4 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.9.0 wasabi-1.1.2\n",
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    3.5.4                         \n",
      "Location         C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.22621-SP0     \n",
      "Python version   3.10.9                        \n",
      "Pipelines                                      \n",
      "\n",
      "Collecting ru-core-news-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.5.0/ru_core_news_sm-3.5.0-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 15.3/15.3 MB 4.4 MB/s eta 0:00:00\n",
      "Collecting pymorphy3>=1.0.0\n",
      "  Downloading pymorphy3-1.2.0-py3-none-any.whl (55 kB)\n",
      "     -------------------------------------- 55.4/55.4 kB 960.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from ru-core-news-sm==3.5.0) (3.5.4)\n",
      "Collecting pymorphy3-dicts-ru\n",
      "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.5.0) (0.7.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.10.11)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.25.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.9.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->ru-core-news-sm==3.5.0) (2.1.1)\n",
      "Installing collected packages: pymorphy3-dicts-ru, pymorphy3, ru-core-news-sm\n",
      "Successfully installed pymorphy3-1.2.0 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy info\n",
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93e90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyconll\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6419176",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = pyconll.load_from_file('ru_syntagrus-ud-train-a.conllu')\n",
    "full_test = pyconll.load_from_file('ru_syntagrus-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427c6138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Анкета NOUN\n",
      ". PUNCT\n",
      "\n",
      "Начальник NOUN\n",
      "областного ADJ\n",
      "управления NOUN\n",
      "связи NOUN\n",
      "Семен PROPN\n",
      "Еремеевич PROPN\n",
      "был AUX\n",
      "человек NOUN\n",
      "простой ADJ\n",
      ", PUNCT\n",
      "приходил VERB\n",
      "на ADP\n",
      "работу NOUN\n",
      "всегда ADV\n",
      "вовремя ADV\n",
      ", PUNCT\n",
      "здоровался VERB\n",
      "с ADP\n",
      "секретаршей NOUN\n",
      "за ADP\n",
      "руку NOUN\n",
      "и CCONJ\n",
      "иногда ADV\n",
      "даже PART\n",
      "писал VERB\n",
      "в ADP\n",
      "стенгазету NOUN\n",
      "заметки NOUN\n",
      "под ADP\n",
      "псевдонимом NOUN\n",
      "\" PUNCT\n",
      "Муха NOUN\n",
      "\" PUNCT\n",
      ". PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in full_train[:2]:\n",
    "    for token in sent:\n",
    "        print(token.form, token.upos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b4fd8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09fc0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая длина предложения 194\n",
      "Наибольшая длина токена 31\n"
     ]
    }
   ],
   "source": [
    "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
    "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
    "print('Наибольшая длина предложения', MAX_SENT_LEN)\n",
    "print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5543b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Анкета', 'NOUN'), ('.', 'PUNCT')],\n",
       " [('Начальник', 'NOUN'),\n",
       "  ('областного', 'ADJ'),\n",
       "  ('управления', 'NOUN'),\n",
       "  ('связи', 'NOUN'),\n",
       "  ('Семен', 'PROPN'),\n",
       "  ('Еремеевич', 'PROPN'),\n",
       "  ('был', 'AUX'),\n",
       "  ('человек', 'NOUN'),\n",
       "  ('простой', 'ADJ'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('приходил', 'VERB'),\n",
       "  ('на', 'ADP'),\n",
       "  ('работу', 'NOUN'),\n",
       "  ('всегда', 'ADV'),\n",
       "  ('вовремя', 'ADV'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('здоровался', 'VERB'),\n",
       "  ('с', 'ADP'),\n",
       "  ('секретаршей', 'NOUN'),\n",
       "  ('за', 'ADP'),\n",
       "  ('руку', 'NOUN'),\n",
       "  ('и', 'CCONJ'),\n",
       "  ('иногда', 'ADV'),\n",
       "  ('даже', 'PART'),\n",
       "  ('писал', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('стенгазету', 'NOUN'),\n",
       "  ('заметки', 'NOUN'),\n",
       "  ('под', 'ADP'),\n",
       "  ('псевдонимом', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('Муха', 'NOUN'),\n",
       "  ('\"', 'PUNCT'),\n",
       "  ('.', 'PUNCT')],\n",
       " [('В', 'ADP'),\n",
       "  ('приемной', 'NOUN'),\n",
       "  ('его', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('утра', 'NOUN'),\n",
       "  ('ожидали', 'VERB'),\n",
       "  ('посетители', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('-', 'PUNCT'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('с', 'ADP'),\n",
       "  ('важными', 'ADJ'),\n",
       "  ('делами', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('а', 'CCONJ'),\n",
       "  ('кое-кто', 'PRON'),\n",
       "  ('и', 'PART'),\n",
       "  ('с', 'ADP'),\n",
       "  ('такими', 'DET'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('которые', 'PRON'),\n",
       "  ('легко', 'ADV'),\n",
       "  ('можно', 'ADV'),\n",
       "  ('было', 'AUX'),\n",
       "  ('решить', 'VERB'),\n",
       "  ('в', 'ADP'),\n",
       "  ('нижестоящих', 'ADJ'),\n",
       "  ('инстанциях', 'NOUN'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('не', 'PART'),\n",
       "  ('затрудняя', 'VERB'),\n",
       "  ('Семена', 'PROPN'),\n",
       "  ('Еремеевича', 'PROPN'),\n",
       "  ('.', 'PUNCT')]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdata_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "347335b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\AppData\\Local\\Temp\\ipykernel_2516\\4208555745.py:2: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  acc_u = unigram_tagger.evaluate(fdata_test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.823732013802982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "acc_u = unigram_tagger.evaluate(fdata_test)\n",
    "display(acc_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba75570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\AppData\\Local\\Temp\\ipykernel_2516\\2907996023.py:2: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  acc_b = bigram_tagger.evaluate(fdata_test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6093886320724006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigram_tagger = BigramTagger(fdata_train)\n",
    "acc_b = bigram_tagger.evaluate(fdata_test)\n",
    "display(acc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2331ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\AppData\\Local\\Temp\\ipykernel_2516\\678438604.py:2: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  acc_t = trigram_tagger.evaluate(fdata_test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1778631421316492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trigram_tagger = TrigramTagger(fdata_train)\n",
    "acc_t = trigram_tagger.evaluate(fdata_test)\n",
    "display(acc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5b6433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_1 = [BigramTagger, TrigramTagger]\n",
    "combination_2 = [TrigramTagger, UnigramTagger]\n",
    "combination_3 = [UnigramTagger, BigramTagger]\n",
    "combination_4 = [BigramTagger, TrigramTagger, UnigramTagger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8615b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\AppData\\Local\\Temp\\ipykernel_2516\\2746214562.py:14: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  acc_bo.append(tag.evaluate(fdata_test))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1750309264926102,\n",
       " 0.21248779217396965,\n",
       " 0.8275343446838986,\n",
       " 0.3623152548994075]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "acc_bo = []\n",
    "\n",
    "for combination in [combination_1, combination_2, combination_3, combination_4]:\n",
    "    backoff = nltk.DefaultTagger('NN') \n",
    "    tag = backoff_tagger(fdata_train,  \n",
    "                         combination,  \n",
    "                         backoff = backoff) \n",
    "\n",
    "    acc_bo.append(tag.evaluate(fdata_test))\n",
    "\n",
    "acc_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aa34e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagger</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnigramTagger &amp; BigramTagger</td>\n",
       "      <td>0.827534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnigramTagger</td>\n",
       "      <td>0.823732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BigramTagger</td>\n",
       "      <td>0.609389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>All taggers</td>\n",
       "      <td>0.362315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TrigramTagger &amp; UnigramTagger</td>\n",
       "      <td>0.212488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TrigramTagger</td>\n",
       "      <td>0.177863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BigramTagger &amp; TrigramTagger</td>\n",
       "      <td>0.175031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Tagger  Accuracy\n",
       "5   UnigramTagger & BigramTagger  0.827534\n",
       "0                  UnigramTagger  0.823732\n",
       "1                   BigramTagger  0.609389\n",
       "6                    All taggers  0.362315\n",
       "4  TrigramTagger & UnigramTagger  0.212488\n",
       "2                  TrigramTagger  0.177863\n",
       "3   BigramTagger & TrigramTagger  0.175031"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Tagger': ['UnigramTagger', 'BigramTagger', 'TrigramTagger', 'BigramTagger & TrigramTagger', 'TrigramTagger & UnigramTagger', 'UnigramTagger & BigramTagger', 'All taggers'], 'Accuracy' : [acc_u, acc_b, acc_t] + acc_bo})\n",
    "result.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d94e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f681ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
       "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
       "       'VERB', 'X'], dtype='<U6')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)\n",
    "test_enc_labels = le.transform(test_label)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e7875d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [CountVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='char'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=1000)] \n",
    "vectorizers_word = [CountVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               TfidfVectorizer(ngram_range=(1, 3), analyzer='word'), \n",
    "               HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=1000)] \n",
    "n_features = [2000, 3000, 5000, 10000]\n",
    "hvectorizer = [HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=feat) for feat in n_features]\n",
    "hvectorizer_word = [HashingVectorizer(ngram_range=(1, 3), analyzer='word', n_features=feat) for feat in n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c280bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.92      0.91      0.92     11247\n",
      "         ADP       0.98      1.00      0.99     10255\n",
      "         ADV       0.92      0.90      0.91      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.88      0.75      0.81      2978\n",
      "        INTJ       0.33      0.36      0.35        11\n",
      "        NOUN       0.92      0.95      0.94     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.86      0.90      0.88      1436\n",
      "        PART       0.95      0.78      0.86      3762\n",
      "        PRON       0.83      0.89      0.86      5346\n",
      "       PROPN       0.79      0.59      0.67      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.68      0.81        53\n",
      "        VERB       0.94      0.94      0.94     12617\n",
      "           X       0.47      0.16      0.24       105\n",
      "\n",
      "    accuracy                           0.93    115000\n",
      "   macro avg       0.85      0.82      0.82    115000\n",
      "weighted avg       0.93      0.93      0.93    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='char', ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.90      0.91      0.91     11247\n",
      "         ADP       0.99      0.99      0.99     10255\n",
      "         ADV       0.92      0.87      0.89      5986\n",
      "         AUX       0.81      0.97      0.89      1058\n",
      "       CCONJ       0.88      0.98      0.93      4276\n",
      "         DET       0.80      0.83      0.82      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.90      0.96      0.93     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.85      0.90      0.87      1436\n",
      "        PART       0.95      0.79      0.86      3762\n",
      "        PRON       0.87      0.84      0.86      5346\n",
      "       PROPN       0.80      0.52      0.63      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.91      0.86      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.93      0.93      0.93     12617\n",
      "           X       0.45      0.09      0.14       105\n",
      "\n",
      "    accuracy                           0.92    115000\n",
      "   macro avg       0.83      0.78      0.79    115000\n",
      "weighted avg       0.92      0.92      0.92    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(analyzer='char', n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.84      0.84      0.84     11247\n",
      "         ADP       0.97      0.98      0.98     10255\n",
      "         ADV       0.83      0.79      0.81      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.80      0.80      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.84      0.90      0.87     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.81      0.82      0.82      1436\n",
      "        PART       0.92      0.78      0.84      3762\n",
      "        PRON       0.84      0.86      0.85      5346\n",
      "       PROPN       0.72      0.45      0.55      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.88      0.84      0.86     12617\n",
      "           X       0.31      0.05      0.08       105\n",
      "\n",
      "    accuracy                           0.89    115000\n",
      "   macro avg       0.79      0.75      0.76    115000\n",
      "weighted avg       0.88      0.89      0.88    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.37      0.54     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.93      0.78      0.85      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.90      0.20      0.33      4276\n",
      "         DET       0.83      0.69      0.75      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.68      0.80     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.89      0.54      0.67      1436\n",
      "        PART       0.97      0.75      0.84      3762\n",
      "        PRON       0.81      0.82      0.82      5346\n",
      "       PROPN       0.94      0.13      0.23      4315\n",
      "       PUNCT       0.37      1.00      0.54     21941\n",
      "       SCONJ       0.78      0.78      0.78      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.43      0.60     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.64    115000\n",
      "   macro avg       0.67      0.47      0.51    115000\n",
      "weighted avg       0.83      0.64      0.65    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.95      0.44      0.60     11247\n",
      "         ADP       0.99      0.48      0.65     10255\n",
      "         ADV       0.96      0.80      0.87      5986\n",
      "         AUX       0.83      0.88      0.85      1058\n",
      "       CCONJ       0.89      0.20      0.33      4276\n",
      "         DET       0.97      0.61      0.75      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.98      0.68      0.80     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.89      0.56      0.69      1436\n",
      "        PART       0.97      0.75      0.84      3762\n",
      "        PRON       0.78      0.89      0.83      5346\n",
      "       PROPN       0.92      0.16      0.27      4315\n",
      "       PUNCT       0.38      1.00      0.55     21941\n",
      "       SCONJ       0.79      0.85      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.97      0.46      0.62     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.65    115000\n",
      "   macro avg       0.68      0.49      0.53    115000\n",
      "weighted avg       0.84      0.65      0.66    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(n_features=1000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.43      0.21      0.28     11247\n",
      "         ADP       0.83      0.47      0.60     10255\n",
      "         ADV       0.59      0.63      0.61      5986\n",
      "         AUX       0.70      0.94      0.80      1058\n",
      "       CCONJ       0.84      0.18      0.30      4276\n",
      "         DET       0.49      0.55      0.52      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.25      0.53      0.34     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.41      0.43      0.42      1436\n",
      "        PART       0.86      0.76      0.81      3762\n",
      "        PRON       0.64      0.76      0.70      5346\n",
      "       PROPN       0.32      0.08      0.13      4315\n",
      "       PUNCT       0.00      0.00      0.00     21941\n",
      "       SCONJ       0.67      0.95      0.78      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.45      0.25      0.32     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.37    115000\n",
      "   macro avg       0.42      0.38      0.37    115000\n",
      "weighted avg       0.39      0.37      0.35    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(analyzer='char', n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.87      0.87      0.87     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.87      0.82      0.84      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.84      0.75      0.80      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.86      0.93      0.89     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.83      0.84      0.83      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.89      0.85      5346\n",
      "       PROPN       0.74      0.41      0.53      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.88      0.89     12617\n",
      "           X       0.38      0.06      0.10       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.81      0.76      0.77    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(analyzer='char', n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.86      0.88      0.87     11247\n",
      "         ADP       0.98      0.98      0.98     10255\n",
      "         ADV       0.89      0.81      0.85      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.82      0.80      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.86      0.93      0.89     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.82      0.85      0.83      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.84      0.87      0.86      5346\n",
      "       PROPN       0.74      0.40      0.52      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.90      0.88      0.89     12617\n",
      "           X       0.24      0.09      0.13       105\n",
      "\n",
      "    accuracy                           0.90    115000\n",
      "   macro avg       0.80      0.76      0.77    115000\n",
      "weighted avg       0.90      0.90      0.90    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(analyzer='char', n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.83      0.86      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.87      0.94      0.90     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.87      0.85      1436\n",
      "        PART       0.94      0.78      0.85      3762\n",
      "        PRON       0.83      0.86      0.85      5346\n",
      "       PROPN       0.76      0.42      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.81      0.90      0.85      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.89      0.90      0.89     12617\n",
      "           X       0.45      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.82      0.77      0.78    115000\n",
      "weighted avg       0.90      0.91      0.90    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(analyzer='char', n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.88      0.88      0.88     11247\n",
      "         ADP       0.98      0.99      0.98     10255\n",
      "         ADV       0.90      0.84      0.87      5986\n",
      "         AUX       0.81      0.97      0.88      1058\n",
      "       CCONJ       0.88      0.97      0.93      4276\n",
      "         DET       0.83      0.78      0.81      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.88      0.94      0.91     27241\n",
      "      NO_TAG       1.00      1.00      1.00       197\n",
      "         NUM       0.84      0.88      0.86      1436\n",
      "        PART       0.94      0.79      0.85      3762\n",
      "        PRON       0.82      0.87      0.85      5346\n",
      "       PROPN       0.78      0.42      0.54      4315\n",
      "       PUNCT       1.00      1.00      1.00     21941\n",
      "       SCONJ       0.82      0.86      0.84      2176\n",
      "         SYM       1.00      0.64      0.78        53\n",
      "        VERB       0.90      0.90      0.90     12617\n",
      "           X       0.71      0.05      0.09       105\n",
      "\n",
      "    accuracy                           0.91    115000\n",
      "   macro avg       0.83      0.77      0.78    115000\n",
      "weighted avg       0.91      0.91      0.90    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(n_features=2000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.50      0.26      0.34     11247\n",
      "         ADP       0.90      0.48      0.62     10255\n",
      "         ADV       0.68      0.69      0.68      5986\n",
      "         AUX       0.75      0.94      0.84      1058\n",
      "       CCONJ       0.89      0.18      0.31      4276\n",
      "         DET       0.67      0.53      0.59      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.62      0.58      0.59     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.53      0.47      0.50      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.69      0.85      0.76      5346\n",
      "       PROPN       0.39      0.10      0.15      4315\n",
      "       PUNCT       0.48      1.00      0.65     21941\n",
      "       SCONJ       0.76      0.90      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.55      0.31      0.39     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.58    115000\n",
      "   macro avg       0.52      0.45      0.45    115000\n",
      "weighted avg       0.62      0.58      0.56    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(n_features=3000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.55      0.30      0.39     11247\n",
      "         ADP       0.92      0.48      0.63     10255\n",
      "         ADV       0.76      0.71      0.74      5986\n",
      "         AUX       0.77      0.94      0.85      1058\n",
      "       CCONJ       0.93      0.18      0.30      4276\n",
      "         DET       0.68      0.63      0.65      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.65      0.60      0.62     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.62      0.48      0.54      1436\n",
      "        PART       0.90      0.78      0.84      3762\n",
      "        PRON       0.76      0.79      0.78      5346\n",
      "       PROPN       0.44      0.12      0.19      4315\n",
      "       PUNCT       0.46      1.00      0.63     21941\n",
      "       SCONJ       0.73      0.95      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.61      0.32      0.42     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.60    115000\n",
      "   macro avg       0.54      0.46      0.47    115000\n",
      "weighted avg       0.65      0.60      0.58    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(n_features=5000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.63      0.33      0.44     11247\n",
      "         ADP       0.91      0.48      0.63     10255\n",
      "         ADV       0.82      0.72      0.77      5986\n",
      "         AUX       0.79      0.95      0.86      1058\n",
      "       CCONJ       0.92      0.19      0.31      4276\n",
      "         DET       0.69      0.70      0.70      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.70      0.61      0.65     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.66      0.48      0.55      1436\n",
      "        PART       0.91      0.76      0.83      3762\n",
      "        PRON       0.79      0.79      0.79      5346\n",
      "       PROPN       0.54      0.13      0.21      4315\n",
      "       PUNCT       0.44      1.00      0.62     21941\n",
      "       SCONJ       0.76      0.88      0.82      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.67      0.36      0.47     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.61    115000\n",
      "   macro avg       0.57      0.47      0.48    115000\n",
      "weighted avg       0.68      0.61      0.59    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HashingVectorizer(n_features=10000, ngram_range=(1, 3))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.73      0.36      0.48     11247\n",
      "         ADP       0.95      0.48      0.64     10255\n",
      "         ADV       0.88      0.74      0.81      5986\n",
      "         AUX       0.81      0.88      0.84      1058\n",
      "       CCONJ       0.88      0.20      0.33      4276\n",
      "         DET       0.72      0.75      0.74      2978\n",
      "        INTJ       0.00      0.00      0.00        11\n",
      "        NOUN       0.77      0.64      0.70     27241\n",
      "      NO_TAG       0.00      0.00      0.00       197\n",
      "         NUM       0.73      0.57      0.64      1436\n",
      "        PART       0.96      0.75      0.84      3762\n",
      "        PRON       0.83      0.78      0.81      5346\n",
      "       PROPN       0.67      0.15      0.24      4315\n",
      "       PUNCT       0.42      1.00      0.59     21941\n",
      "       SCONJ       0.78      0.88      0.83      2176\n",
      "         SYM       0.00      0.00      0.00        53\n",
      "        VERB       0.76      0.40      0.52     12617\n",
      "           X       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.63    115000\n",
      "   macro avg       0.60      0.48      0.50    115000\n",
      "weighted avg       0.73      0.63      0.62    115000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosec\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f1_scores = []\n",
    "acc_scores = []\n",
    "\n",
    "for vectorizer in vectorizers + vectorizers_word + hvectorizer + hvectorizer_word:\n",
    "    X_train = vectorizer.fit_transform(train_tok)\n",
    "    X_test = vectorizer.transform(test_tok[:115000])\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0, max_iter=100)\n",
    "    lr.fit(X_train, train_enc_labels)\n",
    "    pred = lr.predict(X_test)\n",
    "    f1 = f1_score(test_enc_labels[:115000], pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    acc = accuracy_score(test_enc_labels[:115000], pred)\n",
    "    acc_scores.append(acc)\n",
    "    \n",
    "    print(vectorizer)\n",
    "    print(classification_report(test_enc_labels[:115000], pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71fae5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.927836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.921185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.903654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.901786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.896609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.895273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.882224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.663954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.649238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.618026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.594254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.576557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.555726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.345039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  f1_score\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.927836\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.921185\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.903654\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.901786\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.896609\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.895273\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.882224\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.663954\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.649238\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.618026\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.594254\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.576557\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.555726\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.345039"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + hvectorizer + hvectorizer_word,\n",
    "                            'f1_score': f1_scores})\n",
    "result_model.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bb6bcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CountVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.929513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TfidfVectorizer(analyzer='char', ngram_range=(...</td>\n",
       "      <td>0.923609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.907417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.905487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.900330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.898939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HashingVectorizer(analyzer='char', n_features=...</td>\n",
       "      <td>0.885165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TfidfVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.654452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CountVectorizer(ngram_range=(1, 3))</td>\n",
       "      <td>0.640852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HashingVectorizer(n_features=10000, ngram_rang...</td>\n",
       "      <td>0.627357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HashingVectorizer(n_features=5000, ngram_range...</td>\n",
       "      <td>0.612174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HashingVectorizer(n_features=3000, ngram_range...</td>\n",
       "      <td>0.600113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HashingVectorizer(n_features=2000, ngram_range...</td>\n",
       "      <td>0.583965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HashingVectorizer(n_features=1000, ngram_range...</td>\n",
       "      <td>0.365243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Vectorizer  Accuracy\n",
       "0   CountVectorizer(analyzer='char', ngram_range=(...  0.929513\n",
       "1   TfidfVectorizer(analyzer='char', ngram_range=(...  0.923609\n",
       "9   HashingVectorizer(analyzer='char', n_features=...  0.907417\n",
       "8   HashingVectorizer(analyzer='char', n_features=...  0.905487\n",
       "7   HashingVectorizer(analyzer='char', n_features=...  0.900330\n",
       "6   HashingVectorizer(analyzer='char', n_features=...  0.898939\n",
       "2   HashingVectorizer(analyzer='char', n_features=...  0.885165\n",
       "4                 TfidfVectorizer(ngram_range=(1, 3))  0.654452\n",
       "3                 CountVectorizer(ngram_range=(1, 3))  0.640852\n",
       "13  HashingVectorizer(n_features=10000, ngram_rang...  0.627357\n",
       "12  HashingVectorizer(n_features=5000, ngram_range...  0.612174\n",
       "11  HashingVectorizer(n_features=3000, ngram_range...  0.600113\n",
       "10  HashingVectorizer(n_features=2000, ngram_range...  0.583965\n",
       "5   HashingVectorizer(n_features=1000, ngram_range...  0.365243"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model_acc = pd.DataFrame({'Vectorizer': vectorizers + vectorizers_word + hvectorizer + hvectorizer_word,\n",
    "                            'Accuracy': acc_scores})\n",
    "result_model_acc.sort_values('Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d22ab5",
   "metadata": {},
   "source": [
    "На первом месте Accuracy коллаборация триггеров из UnigramTagger & BigramTagger с лучшим результатом - 0.93 Во-втором и в-третьем тестах лидирует CountVectorizer с f1_score 0.927826 и Accuracy 0.929504."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec53293",
   "metadata": {},
   "source": [
    "Задание 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "898c312f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting navec\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from navec) (1.25.0)\n",
      "Installing collected packages: navec\n",
      "Successfully installed navec-0.10.0\n",
      "Collecting slovnet\n",
      "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
      "     -------------------------------------- 46.7/46.7 kB 774.9 kB/s eta 0:00:00\n",
      "Collecting razdel\n",
      "  Using cached razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: navec in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from slovnet) (0.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from slovnet) (1.25.0)\n",
      "Installing collected packages: razdel, slovnet\n",
      "Successfully installed razdel-0.5.0 slovnet-0.6.0\n",
      "Collecting ipymarkup\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from ipymarkup) (3.1.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
      "Installing collected packages: ipymarkup\n",
      "Successfully installed ipymarkup-0.9.0\n",
      "Collecting sklearn_crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tabulate in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (0.8.10)\n",
      "Requirement already satisfied: six in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (1.16.0)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.9-cp310-cp310-win_amd64.whl (139 kB)\n",
      "     -------------------------------------- 139.4/139.4 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rosec\\anaconda3\\lib\\site-packages (from tqdm>=2.0->sklearn_crfsuite) (0.4.6)\n",
      "Installing collected packages: python-crfsuite, sklearn_crfsuite\n",
      "Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n",
      "Collecting patool\n",
      "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.5/77.5 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: patool\n",
      "Successfully installed patool-1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install navec\n",
    "!pip install slovnet\n",
    "!pip install ipymarkup\n",
    "!pip install sklearn_crfsuite\n",
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a9379db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import nltk\n",
    "import csv\n",
    "from razdel import tokenize\n",
    "import pandas as pd\n",
    "\n",
    "from spacy import displacy\n",
    "import ru_core_news_sm\n",
    "\n",
    "from navec import Navec\n",
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce1671b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patool: Extracting collection3.zip ...\n",
      "patool: ... collection3.zip extracted to `collection3'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'collection3'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import patoolib\n",
    "patoolib.extract_archive(\"collection3.zip\", outdir=\"collection3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e01ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_txt = [_ for _ in os.listdir(\"collection3/Collection3/\") if _.endswith(\".txt\")]\n",
    "text_list = []\n",
    "for file in documents_txt:\n",
    "    doc = open('collection3/Collection3/' + file, encoding='utf-8')\n",
    "    text = doc.read()\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d05e6d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия рассчитывает на конструктивное воздейст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Комиссар СЕ критикует ограничительную политику...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пулеметы, автоматы и снайперские винтовки изъя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 октября назначены очередные выборы Верховног...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Следственное управление при прокуратуре требуе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Депутат от \"ЕР\": К отставке А.Сердюкова причас...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>\\nСи Цзиньпин избран генсеком Коммунистической...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>\"Ведомости\" узнали о смене лидера московских е...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>СМИ узнали о кутежах туркменского чиновника на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Вице-мэром Новосибирска по социальным вопросам...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Россия рассчитывает на конструктивное воздейст...\n",
       "1    Комиссар СЕ критикует ограничительную политику...\n",
       "2    Пулеметы, автоматы и снайперские винтовки изъя...\n",
       "3    4 октября назначены очередные выборы Верховног...\n",
       "4    Следственное управление при прокуратуре требуе...\n",
       "..                                                 ...\n",
       "995  Депутат от \"ЕР\": К отставке А.Сердюкова причас...\n",
       "996  \\nСи Цзиньпин избран генсеком Коммунистической...\n",
       "997  \"Ведомости\" узнали о смене лидера московских е...\n",
       "998  СМИ узнали о кутежах туркменского чиновника на...\n",
       "999  Вице-мэром Новосибирска по социальным вопросам...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text = pd.DataFrame({'text': text_list})\n",
    "data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aa5469a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rosec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rosec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c0f32df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Россия', 'JJ'),\n",
       " ('рассчитывает', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('конструктивное', 'NNP'),\n",
       " ('воздействие', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('Грузию', 'VBD'),\n",
       " ('04/08/2008', 'CD'),\n",
       " ('12:08', 'CD'),\n",
       " ('МОСКВА', 'NN'),\n",
       " (',', ','),\n",
       " ('4', 'CD'),\n",
       " ('авг', 'SYM'),\n",
       " ('-', ':'),\n",
       " ('РИА', 'NN'),\n",
       " ('Новости', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Россия', 'JJ'),\n",
       " ('рассчитывает', 'NN'),\n",
       " (',', ','),\n",
       " ('что', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('воздействуют', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('Тбилиси', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('связи', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('обострением', 'NNP'),\n",
       " ('ситуации', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('зоне', 'NNP'),\n",
       " ('грузино-осетинского', 'JJ'),\n",
       " ('конфликта', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Об', 'VB'),\n",
       " ('этом', 'JJ'),\n",
       " ('статс-секретарь', 'JJ'),\n",
       " ('-', ':'),\n",
       " ('заместитель', 'NN'),\n",
       " ('министра', 'JJ'),\n",
       " ('иностранных', 'NNP'),\n",
       " ('дел', 'NNP'),\n",
       " ('России', 'NNP'),\n",
       " ('Григорий', 'NNP'),\n",
       " ('Карасин', 'NNP'),\n",
       " ('заявил', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('телефонном', 'NNP'),\n",
       " ('разговоре', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('заместителем', 'NNP'),\n",
       " ('госсекретаря', 'NNP'),\n",
       " ('США', 'NNP'),\n",
       " ('Дэниэлом', 'NNP'),\n",
       " ('Фридом', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('С', 'JJ'),\n",
       " ('российской', 'NN'),\n",
       " ('стороны', 'NNP'),\n",
       " ('выражена', 'NNP'),\n",
       " ('глубокая', 'NNP'),\n",
       " ('озабоченность', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('связи', 'NNP'),\n",
       " ('с', 'NNP'),\n",
       " ('новым', 'NNP'),\n",
       " ('витком', 'NNP'),\n",
       " ('напряженности', 'NNP'),\n",
       " ('вокруг', 'NNP'),\n",
       " ('Южной', 'NNP'),\n",
       " ('Осетии', 'NNP'),\n",
       " (',', ','),\n",
       " ('противозаконными', 'NNP'),\n",
       " ('действиями', 'NNP'),\n",
       " ('грузинской', 'NNP'),\n",
       " ('стороны', 'NNP'),\n",
       " ('по', 'NNP'),\n",
       " ('наращиванию', 'NNP'),\n",
       " ('своих', 'NNP'),\n",
       " ('вооруженных', 'NNP'),\n",
       " ('сил', 'NNP'),\n",
       " ('в', 'NNP'),\n",
       " ('регионе', 'NNP'),\n",
       " (',', ','),\n",
       " ('бесконтрольным', 'NNP'),\n",
       " ('строительством', 'NNP'),\n",
       " ('фортификационных', 'NNP'),\n",
       " ('сооружений', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('говорится', 'NN'),\n",
       " ('в', 'JJ'),\n",
       " ('сообщении', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('``', '``'),\n",
       " ('Россия', 'JJ'),\n",
       " ('уже', 'NN'),\n",
       " ('призвала', 'NNP'),\n",
       " ('Тбилиси', 'NNP'),\n",
       " ('к', 'NNP'),\n",
       " ('ответственной', 'NNP'),\n",
       " ('линии', 'NNP'),\n",
       " ('и', 'NNP'),\n",
       " ('рассчитывает', 'NNP'),\n",
       " ('также', 'NNP'),\n",
       " ('на', 'NNP'),\n",
       " ('конструктивное', 'NNP'),\n",
       " ('воздействие', 'NNP'),\n",
       " ('со', 'NNP'),\n",
       " ('стороны', 'NNP'),\n",
       " ('Вашингтона', 'NNP'),\n",
       " (\"''\", \"''\"),\n",
       " (',', ','),\n",
       " ('-', ':'),\n",
       " ('сообщил', 'NN'),\n",
       " ('МИД', 'JJ'),\n",
       " ('России', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = data_text.text[0]\n",
    "nltk.pos_tag(nltk.word_tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0b760ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\rosec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\rosec\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "651b73ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('МИД России', 'ORGANIZATION'),\n",
       " ('МОСКВА', 'ORGANIZATION'),\n",
       " ('РИА Новости', 'ORGANIZATION'),\n",
       " ('России Григорий Карасин', 'PERSON'),\n",
       " ('Россия', 'PERSON'),\n",
       " ('Тбилиси', 'PERSON')}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0bb6dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>LOC 0 6</th>\n",
       "      <th>Россия</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T1      LOC 0 6            Россия\n",
       "0    T2    LOC 50 53               США\n",
       "1    T3    LOC 57 63            Грузию\n",
       "2    T4    LOC 87 93            МОСКВА\n",
       "3    T5  ORG 103 114       РИА Новости\n",
       "4    T6  LOC 116 122            Россия\n",
       "5    T7  LOC 141 144               США\n",
       "6    T8  LOC 161 168           Тбилиси\n",
       "7    T9  LOC 301 307            России\n",
       "8   T10  PER 308 324  Григорий Карасин\n",
       "9   T11  LOC 383 386               США\n",
       "10  T12  PER 387 402   Дэниэлом Фридом\n",
       "11  T13  LOC 505 517      Южной Осетии\n",
       "12  T14  LOC 703 709            Россия\n",
       "13  T15  LOC 723 730           Тбилиси\n",
       "14  T16  LOC 815 825        Вашингтона\n",
       "15  T17  ORG 838 841               МИД\n",
       "16  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('collection3/Collection3/001.ann', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "35565ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Россия\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " рассчитывает на конструктивное воздействие \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " на \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Грузию\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</br></br>04/08/2008 12:08</br></br>МОСКВА, 4 авг - \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Россия\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " рассчитывает, что \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " воздействуют на \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Тбилиси\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " в связи с обострением ситуации в зоне грузино-осетинского конфликта. Об этом статс-секретарь - заместитель министра иностранных дел \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    России\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Григорий Карасин\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " заявил в телефонном разговоре с заместителем госсекретаря \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    США\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Дэниэлом Фридом\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>&quot;С российской стороны выражена глубокая озабоченность в связи с новым витком напряженности вокруг \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Южной Осетии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", противозаконными действиями грузинской стороны по наращиванию своих вооруженных сил в регионе, бесконтрольным строительством фортификационных сооружений&quot;, - говорится в сообщении.</br></br>&quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Россия\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " уже призвала \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Тбилиси\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " к ответственной линии и рассчитывает также на конструктивное воздействие со стороны \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Вашингтона\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "&quot;, - сообщил \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    МИД\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    России\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = ru_core_news_sm.load()\n",
    "ny_bb = data_text.text[0]\n",
    "article = nlp(ny_bb)\n",
    "displacy.render(article, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eaf8f56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия PROPN nsubj\n",
      "рассчитывает VERB ROOT\n",
      "на ADP case\n",
      "конструктивное ADJ amod\n",
      "воздействие NOUN obl\n",
      "США PROPN nmod\n",
      "на ADP case\n",
      "Грузию PROPN nmod\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "04/08/2008 PROPN appos\n",
      "12:08 NUM appos\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "МОСКВА PROPN nmod\n",
      ", PUNCT punct\n",
      "4 NUM conj\n",
      "авг PROPN obl\n",
      "- NOUN obl\n",
      "РИА PROPN obl\n",
      "Новости PROPN appos\n",
      ". PUNCT punct\n",
      "Россия PROPN nsubj\n",
      "рассчитывает VERB ROOT\n",
      ", PUNCT punct\n",
      "что SCONJ mark\n",
      "США PROPN nsubj\n",
      "воздействуют VERB ccomp\n",
      "на ADP case\n",
      "Тбилиси PROPN obl\n",
      "в ADP case\n",
      "связи NOUN fixed\n",
      "с ADP fixed\n",
      "обострением NOUN obl\n",
      "ситуации NOUN nmod\n",
      "в ADP case\n",
      "зоне NOUN nmod\n",
      "грузино ADJ amod\n",
      "- ADJ amod\n",
      "осетинского ADJ amod\n",
      "конфликта NOUN nmod\n",
      ". PUNCT punct\n",
      "Об ADP case\n",
      "этом PRON obl\n",
      "статс NOUN nsubj\n",
      "- NOUN nsubj\n",
      "секретарь NOUN nsubj\n",
      "- NOUN nsubj\n",
      "заместитель NOUN nsubj\n",
      "министра NOUN nmod\n",
      "иностранных ADJ amod\n",
      "дел NOUN nmod\n",
      "России PROPN nmod\n",
      "Григорий PROPN appos\n",
      "Карасин PROPN flat:name\n",
      "заявил VERB ROOT\n",
      "в ADP case\n",
      "телефонном ADJ amod\n",
      "разговоре NOUN obl\n",
      "с ADP case\n",
      "заместителем NOUN nmod\n",
      "госсекретаря NOUN nmod\n",
      "США PROPN nmod\n",
      "Дэниэлом PROPN appos\n",
      "Фридом PROPN flat:name\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "С ADP case\n",
      "российской ADJ amod\n",
      "стороны NOUN obl\n",
      "выражена VERB ROOT\n",
      "глубокая ADJ amod\n",
      "озабоченность NOUN nsubj:pass\n",
      "в ADP case\n",
      "связи NOUN fixed\n",
      "с ADP fixed\n",
      "новым ADJ amod\n",
      "витком NOUN obl\n",
      "напряженности NOUN nmod\n",
      "вокруг ADP case\n",
      "Южной ADJ amod\n",
      "Осетии PROPN nmod\n",
      ", PUNCT punct\n",
      "противозаконными ADJ amod\n",
      "действиями NOUN conj\n",
      "грузинской ADJ amod\n",
      "стороны NOUN nmod\n",
      "по ADP case\n",
      "наращиванию NOUN nmod\n",
      "своих DET det\n",
      "вооруженных VERB amod\n",
      "сил NOUN nmod\n",
      "в ADP case\n",
      "регионе NOUN nmod\n",
      ", PUNCT punct\n",
      "бесконтрольным ADJ amod\n",
      "строительством NOUN conj\n",
      "фортификационных ADJ amod\n",
      "сооружений NOUN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "говорится VERB parataxis\n",
      "в ADP case\n",
      "сообщении NOUN obl\n",
      ". PUNCT punct\n",
      "\n",
      "\n",
      " SPACE dep\n",
      "\" PUNCT punct\n",
      "Россия PROPN nsubj\n",
      "уже ADV advmod\n",
      "призвала VERB ROOT\n",
      "Тбилиси PROPN obj\n",
      "к ADP case\n",
      "ответственной ADJ amod\n",
      "линии NOUN obl\n",
      "и CCONJ cc\n",
      "рассчитывает VERB conj\n",
      "также ADV advmod\n",
      "на ADP case\n",
      "конструктивное ADJ amod\n",
      "воздействие NOUN obl\n",
      "со ADP case\n",
      "стороны NOUN fixed\n",
      "Вашингтона PROPN nmod\n",
      "\" PUNCT punct\n",
      ", PUNCT punct\n",
      "- PUNCT punct\n",
      "сообщил VERB parataxis\n",
      "МИД PROPN nsubj\n",
      "России PROPN nmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in article:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "361f1269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 0 6</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1                 2\n",
       "0    T1      LOC 0 6            Россия\n",
       "1    T2    LOC 50 53               США\n",
       "2    T3    LOC 57 63            Грузию\n",
       "3    T4    LOC 87 93            МОСКВА\n",
       "4    T5  ORG 103 114       РИА Новости\n",
       "5    T6  LOC 116 122            Россия\n",
       "6    T7  LOC 141 144               США\n",
       "7    T8  LOC 161 168           Тбилиси\n",
       "8    T9  LOC 301 307            России\n",
       "9   T10  PER 308 324  Григорий Карасин\n",
       "10  T11  LOC 383 386               США\n",
       "11  T12  PER 387 402   Дэниэлом Фридом\n",
       "12  T13  LOC 505 517      Южной Осетии\n",
       "13  T14  LOC 703 709            Россия\n",
       "14  T15  LOC 723 730           Тбилиси\n",
       "15  T16  LOC 815 825        Вашингтона\n",
       "16  T17  ORG 838 841               МИД\n",
       "17  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('collection3/Collection3/001.ann', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "111c23a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия рассчитывает на конструктивное воздействие США на Грузию\n",
      "LOC───                                            LOC    LOC───\n",
      "04/08/2008 12:08\n",
      "МОСКВА, 4 авг - РИА Новости. Россия рассчитывает, что США воздействуют\n",
      "LOC───          ORG────────  LOC───                   LOC             \n",
      " на Тбилиси в связи с обострением ситуации в зоне грузино-осетинского \n",
      "    LOC────                                                           \n",
      "конфликта. Об этом статс-секретарь - заместитель министра иностранных \n",
      "дел России Григорий Карасин заявил в телефонном разговоре с \n",
      "    LOC─── PER─────────────                                 \n",
      "заместителем госсекретаря США Дэниэлом Фридом.\n",
      "                          LOC PER──────────── \n",
      "\"С российской стороны выражена глубокая озабоченность в связи с новым \n",
      "витком напряженности вокруг Южной Осетии, противозаконными действиями \n",
      "                            LOC─────────                              \n",
      "грузинской стороны по наращиванию своих вооруженных сил в регионе, \n",
      "бесконтрольным строительством фортификационных сооружений\", - \n",
      "говорится в сообщении.\n",
      "\"Россия уже призвала Тбилиси к ответственной линии и рассчитывает \n",
      " LOC───              LOC────                                      \n",
      "также на конструктивное воздействие со стороны Вашингтона\", - сообщил \n",
      "                                               LOC───────             \n",
      "МИД России. \n",
      "ORG LOC───  \n"
     ]
    }
   ],
   "source": [
    "text = data_text.text[0]\n",
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')\n",
    "ner = NER.load('slovnet_ner_news_v1.tar')\n",
    "ner.navec(navec)\n",
    "\n",
    "markup = ner(text)\n",
    "show_markup(markup.text, markup.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c20d67fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001.ann', '002.ann', '003.ann', '004.ann', '005.ann', '006.ann', '007.ann', '008.ann', '009.ann', '010.ann', '011.ann', '012.ann', '013.ann', '014.ann', '015 (!).ann', '016.ann', '017.ann', '018.ann', '019.ann', '020.ann', '021.ann', '022.ann', '023.ann', '025.ann', '026.ann', '027.ann', '028.ann', '029.ann', '030.ann', '031.ann', '032.ann', '033.ann', '034.ann', '035.ann', '036.ann', '037.ann', '038.ann', '039.ann', '03_12_12a.ann', '03_12_12b.ann', '03_12_12c.ann', '03_12_12d.ann', '03_12_12g.ann', '03_12_12h.ann', '040.ann', '041.ann', '042.ann', '043.ann', '044.ann', '045.ann', '046.ann', '047.ann', '048.ann', '049.ann', '04_02_13a_abdulatipov.ann', '04_03_13a_sorokin.ann', '04_12_12b.ann', '04_12_12d.ann', '04_12_12f.ann', '04_12_12g.ann', '04_12_12h_corr.ann', '050.ann', '051.ann', '052.ann', '053.ann', '054.ann', '055.ann', '056.ann', '057.ann', '058.ann', '059.ann', '060.ann', '061.ann', '062.ann', '063.ann', '064.ann', '065.ann', '066.ann', '067.ann', '068.ann', '069.ann', '070.ann', '071.ann', '072.ann', '073.ann', '074.ann', '075.ann', '076.ann', '077.ann', '078.ann', '079.ann', '080.ann', '081.ann', '082.ann', '083.ann', '084.ann', '085.ann', '086.ann', '087.ann', '088.ann', '089.ann', '090.ann', '091.ann', '092.ann', '093.ann', '094.ann', '095.ann', '096.ann', '097.ann', '098.ann', '099.ann', '09_01_13.ann', '09_01_13a.ann', '09_01_13c.ann', '09_01_13d.ann', '09_01_13e.ann', '09_01_13h.ann', '09_01_13i.ann', '100.ann', '1000.ann', '1001.ann', '1002.ann', '1003.ann', '1004.ann', '1005.ann', '1006.ann', '1007.ann', '1008.ann', '1009.ann', '101.ann', '1010.ann', '1011.ann', '1012.ann', '1013.ann', '1014.ann', '1015.ann', '1016.ann', '1017.ann', '1018.ann', '1019.ann', '102.ann', '1020.ann', '1021.ann', '1022.ann', '1023.ann', '1024.ann', '1025.ann', '1026.ann', '1027.ann', '1028.ann', '1029.ann', '103.ann', '1030.ann', '1031.ann', '1032.ann', '1033.ann', '1034.ann', '1035.ann', '1036.ann', '1037.ann', '1038.ann', '1039.ann', '104.ann', '1040.ann', '1041.ann', '1042.ann', '1043.ann', '1044.ann', '1045.ann', '1046.ann', '1047.ann', '1048.ann', '1049.ann', '105.ann', '1050.ann', '106.ann', '107.ann', '108.ann', '109.ann', '10_01_13a.ann', '10_01_13d.ann', '10_01_13i.ann', '110.ann', '1100.ann', '1101.ann', '1102.ann', '1103.ann', '1104.ann', '1105.ann', '1106.ann', '1107.ann', '1108.ann', '1109.ann', '111.ann', '1110.ann', '1111.ann', '1112.ann', '1113.ann', '1114.ann', '1115.ann', '1116.ann', '1117.ann', '1118.ann', '1119.ann', '112.ann', '1120.ann', '1121.ann', '1122.ann', '1123.ann', '1124.ann', '1125.ann', '1126.ann', '1127.ann', '1128.ann', '113.ann', '1130.ann', '1131.ann', '1132.ann', '1133.ann', '1134.ann', '1135.ann', '1136.ann', '1137.ann', '1138.ann', '1139.ann', '114.ann', '1140.ann', '1141.ann', '1142.ann', '1143.ann', '1144.ann', '1145.ann', '1146.ann', '1147.ann', '1148.ann', '1149.ann', '115.ann', '1150.ann', '1151.ann', '1152.ann', '1153.ann', '1154.ann', '1155.ann', '1156.ann', '1157.ann', '1158.ann', '1159.ann', '116.ann', '1160.ann', '1161.ann', '1162.ann', '1163.ann', '1164.ann', '1165.ann', '1166.ann', '1167.ann', '1168.ann', '1169.ann', '117.ann', '1170.ann', '1171.ann', '1172.ann', '1173.ann', '1174.ann', '1175.ann', '1176.ann', '1177.ann', '1178.ann', '1179.ann', '118.ann', '1180.ann', '1181.ann', '1182.ann', '1183.ann', '1184.ann', '1185.ann', '1186.ann', '1187.ann', '1188.ann', '1189.ann', '119.ann', '1190.ann', '1191.ann', '1192.ann', '1193.ann', '1194.ann', '1195.ann', '1196.ann', '1197.ann', '1198.ann', '1199.ann', '11_01_13b.ann', '11_01_13e.ann', '120.ann', '1200.ann', '121.ann', '122.ann', '123.ann', '124.ann', '125.ann', '126.ann', '127.ann', '128.ann', '129.ann', '130.ann', '131.ann', '132.ann', '133.ann', '134.ann', '135.ann', '136.ann', '137.ann', '138.ann', '139.ann', '140.ann', '141.ann', '142.ann', '143.ann', '144.ann', '145.ann', '146.ann', '147.ann', '148.ann', '149.ann', '14_01_13c.ann', '14_01_13g.ann', '14_01_13i.ann', '150.ann', '151.ann', '152.ann', '153.ann', '154.ann', '155.ann', '156.ann', '157.ann', '158.ann', '159.ann', '15_01_13a.ann', '15_01_13b.ann', '15_01_13e.ann', '15_01_13f.ann', '160.ann', '161.ann', '162.ann', '163.ann', '164.ann', '165.ann', '166.ann', '167.ann', '168.ann', '169.ann', '170.ann', '171.ann', '172.ann', '173.ann', '174.ann', '175.ann', '176.ann', '177.ann', '178.ann', '179.ann', '180.ann', '181.ann', '182.ann', '183.ann', '184.ann', '185.ann', '186.ann', '187.ann', '188.ann', '189.ann', '190.ann', '191.ann', '192.ann', '193.ann', '194.ann', '195.ann', '196.ann', '197.ann', '198.ann', '199.ann', '19_11_12d.ann', '19_11_12h.ann', '200.ann', '2001.ann', '2002.ann', '2003.ann', '2004.ann', '2005.ann', '2006.ann', '2007.ann', '2008.ann', '2009.ann', '201.ann', '2010.ann', '2011.ann', '2012.ann', '2013.ann', '2014.ann', '2015.ann', '2016.ann', '2017.ann', '2018.ann', '2019.ann', '202.ann', '2020.ann', '2021.ann', '2022.ann', '2023.ann', '2024.ann', '2025.ann', '2026.ann', '2027.ann', '2028.ann', '2029.ann', '203.ann', '2030.ann', '2031.ann', '2032.ann', '2034.ann', '2035.ann', '2036.ann', '2037.ann', '2038.ann', '2039.ann', '204.ann', '2040.ann', '2041.ann', '2042.ann', '2043.ann', '2044.ann', '2045.ann', '2046.ann', '2047.ann', '2048.ann', '2049.ann', '205.ann', '2050.ann', '206.ann', '207.ann', '208.ann', '209.ann', '20_11_12a.ann', '20_11_12b.ann', '20_11_12c.ann', '20_11_12d.ann', '20_11_12i.ann', '210.ann', '211.ann', '212.ann', '213.ann', '214.ann', '215.ann', '216.ann', '217.ann', '218.ann', '219.ann', '21_11_12c.ann', '21_11_12h.ann', '21_11_12i.ann', '21_11_12j.ann', '220.ann', '221.ann', '222.ann', '223.ann', '224.ann', '225.ann', '226.ann', '227.ann', '228.ann', '229.ann', '22_11_12a.ann', '22_11_12c.ann', '22_11_12d.ann', '22_11_12g.ann', '22_11_12h.ann', '22_11_12i.ann', '22_11_12j.ann', '230.ann', '231.ann', '232.ann', '233.ann', '234.ann', '235.ann', '236.ann', '237.ann', '238.ann', '239.ann', '23_11_12a.ann', '23_11_12b.ann', '23_11_12c.ann', '23_11_12d.ann', '23_11_12e.ann', '23_11_12f.ann', '240.ann', '241.ann', '242.ann', '243.ann', '244.ann', '245.ann', '246.ann', '247.ann', '248.ann', '249.ann', '250.ann', '251.ann', '252.ann', '253.ann', '254.ann', '255.ann', '256.ann', '257.ann', '258.ann', '259.ann', '25_12_12a.ann', '25_12_12c.ann', '25_12_12d.ann', '25_12_12e.ann', '260.ann', '261.ann', '262.ann', '263.ann', '264.ann', '265.ann', '266.ann', '267.ann', '268.ann', '269.ann', '26_11_12b.ann', '26_11_12c.ann', '26_11_12e.ann', '26_11_12f.ann', '270.ann', '271.ann', '272.ann', '273.ann', '274.ann', '275.ann', '276.ann', '277.ann', '278.ann', '279.ann', '27_11_12a.ann', '27_11_12c.ann', '27_11_12d.ann', '27_11_12e.ann', '27_11_12j.ann', '280.ann', '281.ann', '282.ann', '283.ann', '284.ann', '285.ann', '286.ann', '287.ann', '288.ann', '289.ann', '28_11_12a.ann', '28_11_12f.ann', '28_11_12g.ann', '28_11_12h.ann', '28_11_12i.ann', '28_11_12j.ann', '290.ann', '291.ann', '292.ann', '293.ann', '294.ann', '295.ann', '296.ann', '297.ann', '298.ann', '299.ann', '29_11_12a.ann', '29_11_12b.ann', '300.ann', '301.ann', '302.ann', '303.ann', '304.ann', '305.ann', '306.ann', '307.ann', '308.ann', '309.ann', '30_11_12b.ann', '30_11_12h.ann', '30_11_12i.ann', '310.ann', '311.ann', '312.ann', '313.ann', '314.ann', '315.ann', '316.ann', '317.ann', '318.ann', '319.ann', '320.ann', '321.ann', '322.ann', '323.ann', '324.ann', '325.ann', '326.ann', '327.ann', '328.ann', '329.ann', '330.ann', '331.ann', '332.ann', '333.ann', '334.ann', '335.ann', '336.ann', '337.ann', '338.ann', '339.ann', '340.ann', '341.ann', '342.ann', '343.ann', '344.ann', '345.ann', '346.ann', '347.ann', '348.ann', '349.ann', '350.ann', '351.ann', '352.ann', '353.ann', '354.ann', '355.ann', '356.ann', '357.ann', '358.ann', '359.ann', '360.ann', '361.ann', '362.ann', '363.ann', '364.ann', '365.ann', '366.ann', '367.ann', '368.ann', '369.ann', '370.ann', '371.ann', '372.ann', '373.ann', '374.ann', '375.ann', '376.ann', '377.ann', '378.ann', '379.ann', '380.ann', '381.ann', '382.ann', '383.ann', '384.ann', '385.ann', '386.ann', '387.ann', '388.ann', '389.ann', '390.ann', '391.ann', '392.ann', '393.ann', '394.ann', '395.ann', '396.ann', '397.ann', '398.ann', '399.ann', '400.ann', '401.ann', '402.ann', '403.ann', '404.ann', '405.ann', '406.ann', '407.ann', '408.ann', '409.ann', '410.ann', '411.ann', '412.ann', '413.ann', '414.ann', '415.ann', '416.ann', '417.ann', '418.ann', '419.ann', '420.ann', '421.ann', '422.ann', '423.ann', '424.ann', '425.ann', '426.ann', '427.ann', '428.ann', '429.ann', '430.ann', '431.ann', '432.ann', '433.ann', '434.ann', '435.ann', '436.ann', '437.ann', '438.ann', '439.ann', '440.ann', '441.ann', '442.ann', '443.ann', '444.ann', '445.ann', '446.ann', '447.ann', '448.ann', '449.ann', '450.ann', '451.ann', '452.ann', '453.ann', '454.ann', '455.ann', '457.ann', '458.ann', '459.ann', '460.ann', '461.ann', '462.ann', '463.ann', '464.ann', '465.ann', '466.ann', '467.ann', '468.ann', '469.ann', '470.ann', '471.ann', '472.ann', '473.ann', '474.ann', '475.ann', '476.ann', '477.ann', '478.ann', '479.ann', '480.ann', '481.ann', '482.ann', '483.ann', '484.ann', '485.ann', '486.ann', '487.ann', '488.ann', '489.ann', '490.ann', '491.ann', '492.ann', '493.ann', '494.ann', '495.ann', '496.ann', '497.ann', '498.ann', '499.ann', '500.ann', '501.ann', '502.ann', '503.ann', '504.ann', '505.ann', '506.ann', '507.ann', '508.ann', '509.ann', '510.ann', '511.ann', '512.ann', '513.ann', '514.ann', '515.ann', '516.ann', '517.ann', '518.ann', '519.ann', '520.ann', '521.ann', '522.ann', '523.ann', '524.ann', '525.ann', '526.ann', '527.ann', '528.ann', '529.ann', '530.ann', '531.ann', '532.ann', '533 (!).ann', '534.ann', '535.ann', '536.ann', '537.ann', '538.ann', '539.ann', '540.ann', '541.ann', '542.ann', '543.ann', '544.ann', '545.ann', '546.ann', '547.ann', '548.ann', '549.ann', '550.ann', '551.ann', '552.ann', '553.ann', '554.ann', '555 (!).ann', '556.ann', '557.ann', '558.ann', '559.ann', '560.ann', '561.ann', '562.ann', '563.ann', '564.ann', '565.ann', '567.ann', '568.ann', '569.ann', '570.ann', '571.ann', '572.ann', '574.ann', '575.ann', '576.ann', '577.ann', '578.ann', '579.ann', '581.ann', '582.ann', '583.ann', '584 (!).ann', '585.ann', '586.ann', '587.ann', '588.ann', '589.ann', '590.ann', '591.ann', '592.ann', '593.ann', '594.ann', '595.ann', '596.ann', '597.ann', '598 (!).ann', '599.ann', '600.ann', '601.ann', '602.ann', '610.ann', '611.ann', '612.ann', '613.ann', '614.ann', '615.ann', '616.ann', '617.ann', '618.ann', '619.ann', '620.ann', '621.ann', '622.ann', '623.ann', '624.ann', '625.ann', '626.ann', '627.ann', '628.ann', '629.ann', '630.ann', '631.ann', '632.ann', '633.ann', 'abdulatipov.ann', 'artjakov.ann', 'Avtovaz.ann', 'blokhin.ann', 'chaves.ann', 'chirkunov.ann', 'kamchatka.ann', 'klinton.ann', 'kuleshov.ann', 'last_01.ann', 'last_02.ann', 'last_03.ann', 'last_04.ann', 'last_05.ann', 'last_06.ann', 'last_07_new.ann', 'last_08.ann', 'last_09.ann', 'last_10.ann', 'last_11.ann', 'last_12.ann', 'last_13.ann', 'last_14.ann', 'last_15.ann', 'last_16.ann', 'last_17.ann', 'last_18.ann', 'last_19.ann', 'last_20.ann', 'last_21.ann', 'last_22.ann', 'last_23.ann', 'last_24.ann', 'last_25.ann', 'last_26.ann', 'last_27.ann', 'last_28.ann', 'last_29.ann', 'last_30_new.ann', 'last_31.ann', 'last_32.ann', 'last_33.ann', 'last_34.ann', 'last_35.ann', 'last_36.ann', 'last_37.ann', 'last_38.ann', 'last_39.ann', 'last_40.ann', 'last_41.ann', 'last_42.ann', 'last_43.ann', 'last_44.ann', 'last_45.ann', 'last_46.ann', 'last_47.ann', 'last_48.ann', 'last_49.ann', 'last_50.ann', 'last_51.ann', 'last_52.ann', 'last_53.ann', 'last_54.ann', 'last_55.ann', 'last_56.ann', 'last_57.ann', 'last_58.ann', 'last_59.ann', 'last_60.ann', 'last_61.ann', 'last_62.ann', 'last_63.ann', 'last_64.ann', 'last_65.ann', 'last_66.ann', 'last_67.ann', 'last_68.ann', 'last_69.ann', 'last_70.ann', 'last_71.ann', 'last_72.ann', 'last_73.ann', 'last_74.ann', 'last_75.ann', 'lenoblast.ann', 'maykl dzhekson.ann', 'mvd.ann', 'mvd2.ann', 'rosobrnadzor.ann', 'ryadovoy chelah.ann', 'semenenko.ann', 'shojgu1.ann', 'shojgu3.ann', 'shojgu4.ann', 'shojgu6.ann', 'si_tzjanpin.ann', 'sobjanin2.ann', 'turkmenija.ann', 'uchitel.ann']\n"
     ]
    }
   ],
   "source": [
    "fileDir = r\"collection3/Collection3/\"\n",
    "fileExt = r\".ann\"\n",
    "documents_ann = [_ for _ in os.listdir(fileDir) if _.endswith(fileExt)]\n",
    "print(documents_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "22c45c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>LOC 0 6</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T2</td>\n",
       "      <td>LOC 50 53</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T3</td>\n",
       "      <td>LOC 57 63</td>\n",
       "      <td>Грузию</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T4</td>\n",
       "      <td>LOC 87 93</td>\n",
       "      <td>МОСКВА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T5</td>\n",
       "      <td>ORG 103 114</td>\n",
       "      <td>РИА Новости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T6</td>\n",
       "      <td>LOC 116 122</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T7</td>\n",
       "      <td>LOC 141 144</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T8</td>\n",
       "      <td>LOC 161 168</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T9</td>\n",
       "      <td>LOC 301 307</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T10</td>\n",
       "      <td>PER 308 324</td>\n",
       "      <td>Григорий Карасин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T11</td>\n",
       "      <td>LOC 383 386</td>\n",
       "      <td>США</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T12</td>\n",
       "      <td>PER 387 402</td>\n",
       "      <td>Дэниэлом Фридом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13</td>\n",
       "      <td>LOC 505 517</td>\n",
       "      <td>Южной Осетии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T14</td>\n",
       "      <td>LOC 703 709</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T15</td>\n",
       "      <td>LOC 723 730</td>\n",
       "      <td>Тбилиси</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>T16</td>\n",
       "      <td>LOC 815 825</td>\n",
       "      <td>Вашингтона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T17</td>\n",
       "      <td>ORG 838 841</td>\n",
       "      <td>МИД</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T18</td>\n",
       "      <td>LOC 842 848</td>\n",
       "      <td>России</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0            1                 2\n",
       "0    T1      LOC 0 6            Россия\n",
       "1    T2    LOC 50 53               США\n",
       "2    T3    LOC 57 63            Грузию\n",
       "3    T4    LOC 87 93            МОСКВА\n",
       "4    T5  ORG 103 114       РИА Новости\n",
       "5    T6  LOC 116 122            Россия\n",
       "6    T7  LOC 141 144               США\n",
       "7    T8  LOC 161 168           Тбилиси\n",
       "8    T9  LOC 301 307            России\n",
       "9   T10  PER 308 324  Григорий Карасин\n",
       "10  T11  LOC 383 386               США\n",
       "11  T12  PER 387 402   Дэниэлом Фридом\n",
       "12  T13  LOC 505 517      Южной Осетии\n",
       "13  T14  LOC 703 709            Россия\n",
       "14  T15  LOC 723 730           Тбилиси\n",
       "15  T16  LOC 815 825        Вашингтона\n",
       "16  T17  ORG 838 841               МИД\n",
       "17  T18  LOC 842 848            России"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = pd.read_csv('collection3/Collection3/001.ann', delimiter='\\t', header=None)\n",
    "ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e372e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "# print(len(data_text))\n",
    "# print(len(documents_ann))\n",
    "# for i in range(len(data_text)):\n",
    "for i in range(len(documents_ann)):\n",
    "    words = []\n",
    "    labels = []\n",
    "    text = data_text['text'][i]\n",
    "    # print(documents_ann[i])\n",
    "    df = pd.read_csv('collection3/Collection3/' + documents_ann[i], delimiter='\\t', header=None, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "    df_ann = pd.DataFrame()\n",
    "    df_ann['Token'] = df.loc[:, 2]\n",
    "    split_1 = [loc.split() for loc in df.loc[:, 1].values]\n",
    "    df_ann['Entity'] = [loc[0] for loc in split_1]\n",
    "       \n",
    "    dic = {}\n",
    "    for j in range(len(df)):\n",
    "        token = df_ann['Token'][j].lower().split()\n",
    "        entity = df_ann['Entity'][j]\n",
    "        for tok in token:\n",
    "            dic[tok] = entity\n",
    "\n",
    "    for token in tokenize(text):\n",
    "        if (token.text.lower() in dic.keys()):\n",
    "            words.append(token.text)\n",
    "            labels.append(dic[token.text.lower()])\n",
    "        else:\n",
    "            words.append(token.text)\n",
    "            labels.append('OUT')\n",
    "    \n",
    "    docs.append([words, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ae3355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Россия', 'рассчитывает', 'на', 'конструктивное', 'воздействие', 'США', 'на', 'Грузию', '04/08/2008', '12', ':', '08', 'МОСКВА', ',', '4', 'авг', '-', 'РИА', 'Новости', '.', 'Россия', 'рассчитывает', ',', 'что', 'США', 'воздействуют', 'на', 'Тбилиси', 'в', 'связи', 'с', 'обострением', 'ситуации', 'в', 'зоне', 'грузино-осетинского', 'конфликта', '.', 'Об', 'этом', 'статс-секретарь', '-', 'заместитель', 'министра', 'иностранных', 'дел', 'России', 'Григорий', 'Карасин', 'заявил', 'в', 'телефонном', 'разговоре', 'с', 'заместителем', 'госсекретаря', 'США', 'Дэниэлом', 'Фридом', '.', '\"', 'С', 'российской', 'стороны', 'выражена', 'глубокая', 'озабоченность', 'в', 'связи', 'с', 'новым', 'витком', 'напряженности', 'вокруг', 'Южной', 'Осетии', ',', 'противозаконными', 'действиями', 'грузинской', 'стороны', 'по', 'наращиванию', 'своих', 'вооруженных', 'сил', 'в', 'регионе', ',', 'бесконтрольным', 'строительством', 'фортификационных', 'сооружений', '\"', ',', '-', 'говорится', 'в', 'сообщении', '.', '\"', 'Россия', 'уже', 'призвала', 'Тбилиси', 'к', 'ответственной', 'линии', 'и', 'рассчитывает', 'также', 'на', 'конструктивное', 'воздействие', 'со', 'стороны', 'Вашингтона', '\"', ',', '-', 'сообщил', 'МИД', 'России', '.']\n",
      "['LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'ORG', 'ORG', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'PER', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'PER', 'PER', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'LOC', 'OUT', 'OUT', 'OUT', 'OUT', 'ORG', 'LOC', 'OUT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(docs[0][0]), print(docs[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bbaba6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия\tLOC\n",
      "рассчитывает\tOUT\n",
      "на\tOUT\n",
      "конструктивное\tOUT\n",
      "воздействие\tOUT\n",
      "США\tLOC\n",
      "на\tOUT\n",
      "Грузию\tLOC\n",
      "04/08/2008\tOUT\n",
      "12\tOUT\n",
      ":\tOUT\n",
      "08\tOUT\n",
      "МОСКВА\tLOC\n",
      ",\tOUT\n",
      "4\tOUT\n",
      "авг\tOUT\n",
      "-\tOUT\n",
      "РИА\tORG\n",
      "Новости\tORG\n",
      ".\tOUT\n",
      "Россия\tLOC\n",
      "рассчитывает\tOUT\n",
      ",\tOUT\n",
      "что\tOUT\n",
      "США\tLOC\n",
      "воздействуют\tOUT\n",
      "на\tOUT\n",
      "Тбилиси\tLOC\n",
      "в\tOUT\n",
      "связи\tOUT\n",
      "с\tOUT\n",
      "обострением\tOUT\n",
      "ситуации\tOUT\n",
      "в\tOUT\n",
      "зоне\tOUT\n",
      "грузино-осетинского\tOUT\n",
      "конфликта\tOUT\n",
      ".\tOUT\n",
      "Об\tOUT\n",
      "этом\tOUT\n",
      "статс-секретарь\tOUT\n",
      "-\tOUT\n",
      "заместитель\tOUT\n",
      "министра\tOUT\n",
      "иностранных\tOUT\n",
      "дел\tOUT\n",
      "России\tLOC\n",
      "Григорий\tPER\n",
      "Карасин\tPER\n",
      "заявил\tOUT\n",
      "в\tOUT\n",
      "телефонном\tOUT\n",
      "разговоре\tOUT\n",
      "с\tOUT\n",
      "заместителем\tOUT\n",
      "госсекретаря\tOUT\n",
      "США\tLOC\n",
      "Дэниэлом\tPER\n",
      "Фридом\tPER\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "С\tOUT\n",
      "российской\tOUT\n",
      "стороны\tOUT\n",
      "выражена\tOUT\n",
      "глубокая\tOUT\n",
      "озабоченность\tOUT\n",
      "в\tOUT\n",
      "связи\tOUT\n",
      "с\tOUT\n",
      "новым\tOUT\n",
      "витком\tOUT\n",
      "напряженности\tOUT\n",
      "вокруг\tOUT\n",
      "Южной\tLOC\n",
      "Осетии\tLOC\n",
      ",\tOUT\n",
      "противозаконными\tOUT\n",
      "действиями\tOUT\n",
      "грузинской\tOUT\n",
      "стороны\tOUT\n",
      "по\tOUT\n",
      "наращиванию\tOUT\n",
      "своих\tOUT\n",
      "вооруженных\tOUT\n",
      "сил\tOUT\n",
      "в\tOUT\n",
      "регионе\tOUT\n",
      ",\tOUT\n",
      "бесконтрольным\tOUT\n",
      "строительством\tOUT\n",
      "фортификационных\tOUT\n",
      "сооружений\tOUT\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "говорится\tOUT\n",
      "в\tOUT\n",
      "сообщении\tOUT\n",
      ".\tOUT\n",
      "\"\tOUT\n",
      "Россия\tLOC\n",
      "уже\tOUT\n",
      "призвала\tOUT\n",
      "Тбилиси\tLOC\n",
      "к\tOUT\n",
      "ответственной\tOUT\n",
      "линии\tOUT\n",
      "и\tOUT\n",
      "рассчитывает\tOUT\n",
      "также\tOUT\n",
      "на\tOUT\n",
      "конструктивное\tOUT\n",
      "воздействие\tOUT\n",
      "со\tOUT\n",
      "стороны\tOUT\n",
      "Вашингтона\tLOC\n",
      "\"\tOUT\n",
      ",\tOUT\n",
      "-\tOUT\n",
      "сообщил\tOUT\n",
      "МИД\tORG\n",
      "России\tLOC\n",
      ".\tOUT\n"
     ]
    }
   ],
   "source": [
    "data, labels = list(zip(*docs))\n",
    "for w, e in zip(data[0], labels[0]):\n",
    "    print(f'{w}\\t{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "65f3fd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>data</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>рассчитывает</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>конструктивное</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>воздействие</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Грузию</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>04/08/2008</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>:</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>08</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>МОСКВА</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>авг</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>РИА</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Новости</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>рассчитывает</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>что</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>США</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>воздействуют</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>на</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>Тбилиси</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>связи</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>с</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>обострением</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>ситуации</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>в</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>зоне</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>грузино-осетинского</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>конфликта</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>Об</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>этом</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>статс-секретарь</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>заместитель</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>министра</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>иностранных</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>дел</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>России</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "      <td>Григорий</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>Карасин</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "      <td>заявил</td>\n",
       "      <td>OUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id                 data entities\n",
       "0         0               Россия      LOC\n",
       "1         0         рассчитывает      OUT\n",
       "2         0                   на      OUT\n",
       "3         0       конструктивное      OUT\n",
       "4         0          воздействие      OUT\n",
       "5         0                  США      LOC\n",
       "6         0                   на      OUT\n",
       "7         0               Грузию      LOC\n",
       "8         0           04/08/2008      OUT\n",
       "9         0                   12      OUT\n",
       "10        0                    :      OUT\n",
       "11        0                   08      OUT\n",
       "12        0               МОСКВА      LOC\n",
       "13        0                    ,      OUT\n",
       "14        0                    4      OUT\n",
       "15        0                  авг      OUT\n",
       "16        0                    -      OUT\n",
       "17        0                  РИА      ORG\n",
       "18        0              Новости      ORG\n",
       "19        0                    .      OUT\n",
       "20        0               Россия      LOC\n",
       "21        0         рассчитывает      OUT\n",
       "22        0                    ,      OUT\n",
       "23        0                  что      OUT\n",
       "24        0                  США      LOC\n",
       "25        0         воздействуют      OUT\n",
       "26        0                   на      OUT\n",
       "27        0              Тбилиси      LOC\n",
       "28        0                    в      OUT\n",
       "29        0                связи      OUT\n",
       "30        0                    с      OUT\n",
       "31        0          обострением      OUT\n",
       "32        0             ситуации      OUT\n",
       "33        0                    в      OUT\n",
       "34        0                 зоне      OUT\n",
       "35        0  грузино-осетинского      OUT\n",
       "36        0            конфликта      OUT\n",
       "37        0                    .      OUT\n",
       "38        0                   Об      OUT\n",
       "39        0                 этом      OUT\n",
       "40        0      статс-секретарь      OUT\n",
       "41        0                    -      OUT\n",
       "42        0          заместитель      OUT\n",
       "43        0             министра      OUT\n",
       "44        0          иностранных      OUT\n",
       "45        0                  дел      OUT\n",
       "46        0               России      LOC\n",
       "47        0             Григорий      PER\n",
       "48        0              Карасин      PER\n",
       "49        0               заявил      OUT"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sent_id': [i for j in [[i] * len(s) for i, s in enumerate(data)] for i in j],\n",
    "                   'data': [i for j in data for i in j],\n",
    "                   'entities': [i for j in labels for i in j]})\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d4a2d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s['data'].values.tolist(), \n",
    "                                                           s['entities'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('sent_id').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(df)\n",
    "\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fd85118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower()\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f7bd1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fad7748a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'в',\n",
       " 'word[-3:]': 'в',\n",
       " 'word[-2:]': 'в',\n",
       " 'word.isdigit()': False,\n",
       " '-1:word.lower()': 'изъяты',\n",
       " '+1:word.lower()': 'арендуемом'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2a863a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "647c80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c93868f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.3 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', # Градиентный спуск с использованием метода L-BFGS\n",
    "    c1=0.1, # Коэффициент для регуляризации L1\n",
    "    c2=0.1, # Коэффициент для регуляризации L2\n",
    "    max_iterations=1000, # Максимальное количество итераций\n",
    "    all_possible_transitions=True, # Генерация объектов (не встречающихся в обучающих данных)\n",
    "    verbose=False # Выключение режима тренировки\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d598d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities = sorted(df.entities.unique().tolist())\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d58d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9464472957366774"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8308e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dec7d524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': 'беженцев',\n",
       " 'word[-3:]': 'цев',\n",
       " 'word[-2:]': 'ев',\n",
       " 'word.isdigit()': False}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "X[1][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3ab231c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8fee271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:700]\n",
    "X_test = X[700:]\n",
    "y_train = y[:700]\n",
    "y_test = y[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f480b506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=1000,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ce8fc305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entities = sorted(df.entities.unique().tolist())\n",
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9e425e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9414616794196085"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230082f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81f843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
